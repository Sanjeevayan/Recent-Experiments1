{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://appliedmachinelearning.blog/2018/01/18/conventional-approach-to-text-classification-clustering-using-k-nearest-neighbor-k-means-python-implementation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    " \n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    " \n",
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    y = processed.split()\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 sentences of following three classes on which K-NN classification and K-means clustering is performed : \n",
      "1. Cricket \n",
      "2. Artificial Intelligence \n",
      "3. Chemistry\n"
     ]
    }
   ],
   "source": [
    "print (\"There are 10 sentences of following three classes on which K-NN classification and K-means clustering\"\\\n",
    "         \" is performed : \\n1. Cricket \\n2. Artificial Intelligence \\n3. Chemistry\")\n",
    "\n",
    " \n",
    "train_clean_sentences = []\n",
    "path = \"/Users/KumarSanjeev/Desktop/Test2.txt\"\n",
    "fp = open(path,'r')\n",
    "for line in fp:\n",
    "   \n",
    "    line = line.strip()\n",
    "    cleaned = clean(line)\n",
    "  \n",
    "    cleaned = ' '.join(cleaned)\n",
    "    train_clean_sentences.append(cleaned)\n",
    " \n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(train_clean_sentences)\n",
    " \n",
    "# Creating true labels for 30 training sentences\n",
    "y_train = np.zeros(30)\n",
    "y_train[10:20] = 1\n",
    "y_train[20:30] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-5093e3f50e80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Clustering the training 30 sentences with K-means technique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodelkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [31, 30]"
     ]
    }
   ],
   "source": [
    "modelknn = KNeighborsClassifier(n_neighbors=5)\n",
    "modelknn.fit(X,y_train)\n",
    " \n",
    "# Clustering the training 30 sentences with K-means technique\n",
    "modelkmeans = KMeans(n_clusters=3, init='k-means++', max_iter=200, n_init=100)\n",
    "modelkmeans.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Must fit neighbors before querying.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-3ca4a4a444bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrue_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Cricket'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chemistry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpredicted_labels_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpredicted_labels_kmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must fit neighbors before querying.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Must fit neighbors before querying."
     ]
    }
   ],
   "source": [
    "# Predicting it on test data : Testing Phase\n",
    "test_sentences = [\"Chemical compunds are used for preparing bombs based on some reactions\",\\\n",
    "\"Cricket is a boring game where the batsman only enjoys the game\",\\\n",
    "\"Machine learning is a area of Artificial intelligence\"]\n",
    " \n",
    "test_clean_sentence = []\n",
    "for test in test_sentences:\n",
    "    cleaned_test = clean(test)\n",
    "    cleaned = ' '.join(cleaned_test)\n",
    "    cleaned = re.sub(r\"\\d+\",\"\",cleaned)\n",
    "    test_clean_sentence.append(cleaned)\n",
    " \n",
    "Test = vectorizer.transform(test_clean_sentence)\n",
    " \n",
    "true_test_labels = ['Cricket','AI','Chemistry']\n",
    "predicted_labels_knn = modelknn.predict(Test)\n",
    "predicted_labels_kmeans = modelkmeans.predict(Test)\n",
    " \n",
    "print (\"\\nBelow 3 sentences will be predicted against the learned nieghbourhood and learned clusters:\\n1. \",\\\n",
    "test_sentences[0],\"\\n2. \",test_sentences[1],\"\\n3. \",test_sentences[2])\n",
    "print (\"\\n-------------------------------PREDICTIONS BY KNN------------------------------------------\")\n",
    "print (\"\\n\",test_sentences[0],\":\",true_test_labels[np.int(predicted_labels_knn[0])],\\\n",
    "\"\\n\",test_sentences[1],\":\",true_test_labels[np.int(predicted_labels_knn[1])],\\\n",
    "\"\\n\",test_sentences[2],\":\",true_test_labels[np.int(predicted_labels_knn[2])])\n",
    " \n",
    "print (\"\\n-------------------------------PREDICTIONS BY K-Means--------------------------------------\")\n",
    "print (\"\\nIndex of Cricket cluster : \",Counter(modelkmeans.labels_[0:10]).most_common(1)[0][0])\n",
    "print (\"Index of Artificial Intelligence cluster : \",Counter(modelkmeans.labels_[10:20]).most_common(1)[0][0])\n",
    "print (\"Index of Chemistry cluster : \",Counter(modelkmeans.labels_[20:30]).most_common(1)[0][0])\n",
    " \n",
    "print (\"\\n\",test_sentences[0],\":\",predicted_labels_kmeans[0],\\\n",
    "\"\\n\",test_sentences[1],\":\",predicted_labels_kmeans[1],\\\n",
    "\"\\n\",test_sentences[2],\":\",predicted_labels_kmeans[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    " \n",
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    y = processed.split()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"The spell of arms and voices: the white arms of roads, their promise of close embraces and the black arms of tall ships that stand against the moon, their tale of distant nations. They are held out to say: We are alone--come.And the voices say with them: We are your kinsmen.And the air is thick with their company as they call to me, their kinsman, making ready to go, shaking the wings of their exultant and terrible youth. Mother is putting my new secondhand clothes in order. She prays now, she says, that I may learn in my own life and away from home and friends what the heart is and what it feels. Amen. So be it. Welcome, O life, I go to encounter for the millionth time the reality of experience and to forge in the smithy of my soul the uncreated conscience of my race.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The spell of arms and voices: the white arms of roads, their promise of close embraces and the black arms of tall ships that stand against the moon, their tale of distant nations. They are held out to say: We are alone--come.And the voices say with them: We are your kinsmen.And the air is thick with their company as they call to me, their kinsman, making ready to go, shaking the wings of their exultant and terrible youth. Mother is putting my new secondhand clothes in order. She prays now, she says, that I may learn in my own life and away from home and friends what the heart is and what it feels. Amen. So be it. Welcome, O life, I go to encounter for the millionth time the reality of experience and to forge in the smithy of my soul the uncreated conscience of my race.'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-148-984ac7bed4fc>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-148-984ac7bed4fc>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    a = [i for i in doc.lower().split() if i not in stop]\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in doc.lower().split():\n",
    "    if i not in stop:\n",
    "        #print(i)\n",
    "a = [i for i in doc.lower().split() if i not in stop]  \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spell arms voices: white arms roads, promise close embraces black arms tall ships stand moon, tale distant nations. held say: alone--come.and voices say them: kinsmen.and air thick company call me, kinsman, making ready go, shaking wings exultant terrible youth. mother putting new secondhand clothes order. prays now, says, may learn life away home friends heart feels. amen. it. welcome, life, go encounter millionth time reality experience forge smithy soul uncreated conscience race.'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = \" \".join ([i for i in doc.lower().split() if i not in stop])\n",
    "a = [i for i in doc.lower().split() if i not in stop]  \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'punc_free' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-0732f49d0de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpunc_free\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'punc_free' is not defined"
     ]
    }
   ],
   "source": [
    "normalized = \" \".join(lemmatizer.lemmatize(word) for word in punc_free.split())\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "spell\n",
      "of\n",
      "arm\n",
      "and\n",
      "voices:\n",
      "the\n",
      "white\n",
      "arm\n",
      "of\n",
      "roads,\n",
      "their\n",
      "promise\n",
      "of\n",
      "close\n",
      "embrace\n",
      "and\n",
      "the\n",
      "black\n",
      "arm\n",
      "of\n",
      "tall\n",
      "ship\n",
      "that\n",
      "stand\n",
      "against\n",
      "the\n",
      "moon,\n",
      "their\n",
      "tale\n",
      "of\n",
      "distant\n",
      "nations.\n",
      "They\n",
      "are\n",
      "held\n",
      "out\n",
      "to\n",
      "say:\n",
      "We\n",
      "are\n",
      "alone--come.And\n",
      "the\n",
      "voice\n",
      "say\n",
      "with\n",
      "them:\n",
      "We\n",
      "are\n",
      "your\n",
      "kinsmen.And\n",
      "the\n",
      "air\n",
      "is\n",
      "thick\n",
      "with\n",
      "their\n",
      "company\n",
      "a\n",
      "they\n",
      "call\n",
      "to\n",
      "me,\n",
      "their\n",
      "kinsman,\n",
      "making\n",
      "ready\n",
      "to\n",
      "go,\n",
      "shaking\n",
      "the\n",
      "wing\n",
      "of\n",
      "their\n",
      "exultant\n",
      "and\n",
      "terrible\n",
      "youth.\n",
      "Mother\n",
      "is\n",
      "putting\n",
      "my\n",
      "new\n",
      "secondhand\n",
      "clothes\n",
      "in\n",
      "order.\n",
      "She\n",
      "prays\n",
      "now,\n",
      "she\n",
      "says,\n",
      "that\n",
      "I\n",
      "may\n",
      "learn\n",
      "in\n",
      "my\n",
      "own\n",
      "life\n",
      "and\n",
      "away\n",
      "from\n",
      "home\n",
      "and\n",
      "friend\n",
      "what\n",
      "the\n",
      "heart\n",
      "is\n",
      "and\n",
      "what\n",
      "it\n",
      "feels.\n",
      "Amen.\n",
      "So\n",
      "be\n",
      "it.\n",
      "Welcome,\n",
      "O\n",
      "life,\n",
      "I\n",
      "go\n",
      "to\n",
      "encounter\n",
      "for\n",
      "the\n",
      "millionth\n",
      "time\n",
      "the\n",
      "reality\n",
      "of\n",
      "experience\n",
      "and\n",
      "to\n",
      "forge\n",
      "in\n",
      "the\n",
      "smithy\n",
      "of\n",
      "my\n",
      "soul\n",
      "the\n",
      "uncreated\n",
      "conscience\n",
      "of\n",
      "my\n",
      "race.\n"
     ]
    }
   ],
   "source": [
    "for word in doc.split():\n",
    "    print(lemma.lemmatize(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/KumarSanjeev/Desktop/Test2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/KumarSanjeev/Desktop/Test2.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(path,\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cricket is a bat and ball game played between two teams of eleven players each on a cricket field.\n",
      "\n",
      "2. Each phase of play is called an innings during which one team bats, attempting to score as many runs as possible.\n",
      "\n",
      "3. The teams have one or two innings apiece and, when the first innings ends, the teams swap roles for the next innings\n",
      "\n",
      "4. Before a match begins, the two team captains meet on the pitch for the toss of a coin to determine which team will bat first.\n",
      "\n",
      "5. Two batsmen and eleven fielders then enter the field and play begins when a member of the fielding team, known as the bowler, delivers the ball.\n",
      "\n",
      "6. The most common dismissal in cricket match are bowled, when the bowler hits the stumps directly with the ball and dislodges the bails. Batsman gets out.\n",
      "\n",
      "7. Runs are scored by two main methods: either by hitting the ball hard enough for it to cross the boundary, or by the two batsmen swapping ends.\n",
      "\n",
      "8. The main objective of each team is to score more runs than their opponents.\n",
      "\n",
      "9. If the team batting last is all out having scored fewer runs than their opponents, they are said to have \"lost by n runs\".\n",
      "\n",
      "10. The role of striker batsman is to prevent the ball from hitting the stumps by using his bat and, simultaneously, to strike it well enough to score runs\n",
      "\n",
      "11. Artificial intelligence is intelligence exhibited by machines, rather than humans or other animals. \n",
      "\n",
      "12. the field of AI research defines itself as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of success at some goal\n",
      "\n",
      "13. The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner.\n",
      "\n",
      "14. Natural language processing[77] gives machines the ability to read and understand human language and extract intelligence from it.\n",
      "\n",
      "15. AI researchers developed sophisticated mathematical tools to solve specific subproblems. These tools are truly scientific, in the sense that their results are both measurable and verifiable.\n",
      "\n",
      "16. An intelligent agent is a system that perceives its environment and takes actions which maximize its chances of success.\n",
      "\n",
      "17. AI techniques have become an essential part of the technology industry, helping to solve many challenging problems in computer science.\n",
      "\n",
      "18. Recent advancements in AI, and specifically in machine learning, have contributed to the growth of Autonomous Things such as drones and self-driving cars.\n",
      "\n",
      "19. AI research was revived by the commercial success of expert systems,[28] a form of AI program that simulated the knowledge and analytical skills of human experts.\n",
      "\n",
      "20. Advanced statistical techniques (loosely known as deep learning), access to large amounts of data and faster computers enabled advances in machine learning and perception.\n",
      "\n",
      "21. A compound is a pure chemical substance composed of more than one element and the properties of a compound bear little similarity to those of its elements.\n",
      "\n",
      "22. Since the properties of an element are mostly determined by its electron configuration, the properties of the elements likewise show recurring patterns or periodic behaviour.\n",
      "\n",
      "23. The property of inertness of noble gases makes them very suitable in chemicals where reactions are not wanted.\n",
      "\n",
      "24. The atom is also the smallest entity that can be envisaged to retain the chemical properties of the element, such as electronegativity, ionization potential and preferred oxidation state.\n",
      "\n",
      "25. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus\n",
      "\n",
      "26. The atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space called the electron cloud.\n",
      "\n",
      "27. A chemical reaction is a transformation of some substances into one or more different substances.\n",
      "\n",
      "28. Chemistry is sometimes called the central science because it bridges other natural sciences, including physics, geology and biology.\n",
      "\n",
      "29. Chemistry includes topics such as the properties of individual atoms and how atoms form chemical bonds to create chemical compounds.\n",
      "\n",
      "30. Chemistry is a branch of physical science that studies the composition, structure of atoms, properties and change of matter.\n"
     ]
    }
   ],
   "source": [
    "for line in fp:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSubject: posting\\n\\nhi , ' m work phonetics project modern irish ' m hard source . anyone recommend book article english ? ' , specifically interest palatal ( slender ) consonant , work helpful too . thank ! laurel sutton ( sutton @ garnet . berkeley . edu\\n\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\"\n",
    "Subject: posting\n",
    "\n",
    "hi , ' m work phonetics project modern irish ' m hard source . anyone recommend book article english ? ' , specifically interest palatal ( slender ) consonant , work helpful too . thank ! laurel sutton ( sutton @ garnet . berkeley . edu\n",
    "\n",
    "\"\"\"\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-5ef83c81b88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmail\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmail\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#Body of email is only 3rd line of text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/'"
     ]
    }
   ],
   "source": [
    "emails = \"/Users/KumarSanjeev/Desktop/Mail.txt\"\n",
    "all_words = []       \n",
    "for mail in emails:    \n",
    "    with open(mail) as m:\n",
    "        for i,line in enumerate(m):\n",
    "                if i == 2:  #Body of email is only 3rd line of text file\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "     \n",
    "    dictionary = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', ',', \"'\", 'm', 'work', 'phonetics', 'project', 'modern', 'irish', \"'\", 'm', 'hard', 'source', '.', 'anyone', 'recommend', 'book', 'article', 'english', '?', \"'\", ',', 'specifically', 'interest', 'palatal', '(', 'slender', ')', 'consonant', ',', 'work', 'helpful', 'too', '.', 'thank', '!', 'laurel', 'sutton', '(', 'sutton', '@', 'garnet', '.', 'berkeley', '.', 'edu']\n",
      "['hi', ',', \"'\", 'm', 'work', 'phonetics', 'project', 'modern', 'irish', \"'\", 'm', 'hard', 'source', '.', 'anyone', 'recommend', 'book', 'article', 'english', '?', \"'\", ',', 'specifically', 'interest', 'palatal', '(', 'slender', ')', 'consonant', ',', 'work', 'helpful', 'too', '.', 'thank', '!', 'laurel', 'sutton', '(', 'sutton', '@', 'garnet', '.', 'berkeley', '.', 'edu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_values([1, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = \"/Users/KumarSanjeev/Desktop/Mail.txt\"\n",
    "fp = open(emails,\"r\")\n",
    "all_words = []\n",
    "for i,line in enumerate(fp):\n",
    "    #print(i,line)\n",
    "    if i ==3:\n",
    "        #words = line.split()\n",
    "        print(words)\n",
    "        all_words += words\n",
    "        \n",
    "print(all_words)\n",
    "\n",
    "dictionary = Counter(all_words)\n",
    "dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/KumarSanjeev/Desktop/Mail.txt'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-c8aa99c47ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_to_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlist_to_remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_to_remove\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "list_to_remove = dictionary.keys()\n",
    "list_to_remove\n",
    "for item in list_to_remove:\n",
    "    if item.isalpha() == False: \n",
    "        del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "        del dictionary[item]\n",
    "dictionary = dictionary.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hi', 'work', 'phonetics', 'project', 'modern', 'irish', 'hard', 'source', '.', 'anyone', 'recommend', 'book', 'article', 'english', '?', 'specifically', 'interest', 'palatal', '(', 'slender', ')', 'consonant', 'helpful', 'too', 'thank', '!', 'laurel', 'sutton', '@', 'garnet', 'berkeley', 'edu'])\n",
      "-----\n",
      "too\n",
      "edu\n"
     ]
    }
   ],
   "source": [
    "list_to_remove = dictionary.keys()\n",
    "print(list_to_remove)\n",
    "\n",
    "\n",
    "print(\"-----\")\n",
    "for item in list_to_remove:\n",
    "    if len(item)==3:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
