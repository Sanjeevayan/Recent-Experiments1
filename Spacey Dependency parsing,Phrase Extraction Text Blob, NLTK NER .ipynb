{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Blob Phrases are: ['am', 'new macbook']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "\n",
    "sample1 = \"Am I entitled for a new MacBook? \"\n",
    "sample2 = \"I want a laptop\"\n",
    "sample3 = \"what is a domain account for MacBook?\"\n",
    "\n",
    "\n",
    "\n",
    "def phrase_identify(text):\n",
    "    extractor = ConllExtractor()\n",
    "    blob = TextBlob(text,np_extractor=extractor)\n",
    "\n",
    "    return (blob.noun_phrases)\n",
    "\n",
    "\n",
    "print (\"Text Blob Phrases are:\",phrase_identify(sample1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
    "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "    print(chunked)\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk\n",
    "\n",
    "#my_sent = \"WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\"\n",
    "text1 = \"How to raise service requests for Laptop in India\"\n",
    "sample1 = \"Am I entitled for a new laptop? \"\n",
    "sample2 = \"I want a Laptop\"\n",
    "sample3 = \"what is a domain account for MacBook?\"\n",
    "sample4 = \"I need to reset domain password\"\n",
    "\n",
    "\n",
    "print(\"NLTK phrases are\",get_continuous_chunks(text1))\n",
    "print(\"NLTK phrases are\",get_continuous_chunks(sample4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phrase Extraction \n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# doc1 = nlp(u\"The boys need a new laptop\")\n",
    "# doc = nlp(u\"I need to reset domain password\")\n",
    "# #print (list(doc.noun_chunks))\n",
    "# final_chunks = []\n",
    "# for chunk in doc1.noun_chunks:\n",
    "#     final_chunks.append(chunk)\n",
    "# print (final_chunks)    \n",
    "#     #print(\"Chunks are:\",final_chunks.append(chunk))\n",
    "# #     print(chunk.root.dep_ ,chunk.root.text)\n",
    "# #     if 'dobj'  in chunk.root.dep_:\n",
    "# #         print(chunk.root.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want computer accessories.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' I', 'want', 'computer accessories']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Phrase Extraction \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#doc = nlp(u\"The Boys want to reset domain password.\")\n",
    "stop_word = [\"a\",\"an\",\"the\",\"my\",\"new\"]\n",
    "string = input()\n",
    "new_doc = ''\n",
    "for i in string.split():\n",
    "    if i in stop_word:\n",
    "        continue\n",
    "    else :\n",
    "        new_doc = new_doc+' '+i\n",
    "doc1 = nlp(new_doc)\n",
    "\n",
    "list1 = []      \n",
    "for chunk in doc1.noun_chunks:\n",
    "    list1.append(chunk.text)\n",
    "list1.append(chunk.root.head.text)\n",
    "list1[-1] ,list1[-2] = list1[-2] ,list1[-1]\n",
    "list1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"computer:accessories\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"computer:accessories\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"can_be\": [\n",
      "                \"computer:accessories\",\n",
      "                \"loaner:equipment\"\n",
      "            ],\n",
      "            \"is_a\": [\n",
      "                \"computer:accessories\",\n",
      "                \"it:services\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"desktop:computer\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"desktop:computer\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"is_a\": [\n",
      "                \"laptop\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"e-mail:service\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"e-mail:service\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"can_be\": [\n",
      "                \"mail:box:quota\",\n",
      "                \"new:e-mail:account\"\n",
      "            ],\n",
      "            \"is_a\": [\n",
      "                \"it:services\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"it:services\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"it:services\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"can_be\": [\n",
      "                \"computer:accessories\",\n",
      "                \"e-mail:service\",\n",
      "                \"laptop\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"laptop\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"laptop\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"can_be\": [\n",
      "                \"desktop:computer\",\n",
      "                \"tablet\"\n",
      "            ],\n",
      "            \"is_a\": [\n",
      "                \"it:services\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"loaner:equipment\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"loaner:equipment\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"is_a\": [\n",
      "                \"computer:accessories\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"mail:box:quota\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"mail:box:quota\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"is_a\": [\n",
      "                \"e-mail:service\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"new:e-mail:account\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"new:e-mail:account\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"is_a\": [\n",
      "                \"e-mail:service\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"tablet\": {\n",
      "        \"desc\": \"\",\n",
      "        \"id\": \"tablet\",\n",
      "        \"name\": \"\",\n",
      "        \"other\": {},\n",
      "        \"relations\": {\n",
      "            \"is_a\": [\n",
      "                \"laptop\"\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pronto\n",
    "ont = pronto.Ontology('/Users/kumarsanjeev/Desktop/Combined.owl')\n",
    "#print(ont.obo)\n",
    "ontJSON = ont.json.lower()\n",
    "print(ontJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = json.loads(ontJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computer:accessories'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RequestOffering=list1[-1].replace(' ' , ':').lower()\n",
    "RequestOffering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['computer:accessories', 'loaner:equipment']\n",
      "I would like to have new loaner equipment .\n",
      "I want to have new computer accessories .\n",
      "I want new computer accessories .\n",
      "I would like to have new loaner equipment .\n",
      "I want to have new loaner equipment .\n",
      "I need new computer accessories .\n",
      "I want to have new loaner equipment .\n",
      "I need new loaner equipment .\n",
      "I would like to have new loaner equipment .\n",
      "I would like to have new loaner equipment .\n",
      "I want to have new computer accessories .\n",
      "I want new loaner equipment .\n",
      "I want to have new computer accessories .\n",
      "I want new loaner equipment .\n",
      "I want to have new loaner equipment .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "try:\n",
    "    b = d[RequestOffering][\"relations\"][\"can_be\"]\n",
    "    print(b)\n",
    "except KeyError:\n",
    "    print(\"Not Found\")\n",
    "    b=[]\n",
    "for _ in range(15):\n",
    "    if len(b) == 0:\n",
    "        print(\"Ontology Not Found then take user input\")\n",
    "        obj = [input().split(',')][0]\n",
    "        for _ in range(15):\n",
    "            subj = [\"I\"]\n",
    "            verb = [\"want\",\"need\",\"want to have\",\"would like to have\"]# Pattern words: User will have to provide keywords for the verbs to dentify the patterns. \n",
    "            adj = [\"new\"]\n",
    "            l = [subj,verb,adj,obj,\".\"] \n",
    "            m = ' '.join([random.choice(i) for i in l])\n",
    "            print(m)\n",
    "        break\n",
    "    else:\n",
    "        subj = [\"I\"]\n",
    "        verb = [\"want\",\"need\",\"want to have\",\"would like to have\"]# Pattern words: User will have to provide keywords for the verbs to dentify the patterns. \n",
    "        adj = [\"new\"]\n",
    "        obj = []\n",
    "        for i in b:\n",
    "            obj.append(i)\n",
    "\n",
    "        l=[subj,verb,adj,obj,\".\"] \n",
    "        m = ' '.join([random.choice(i) for i in l])\n",
    "        print (m.replace(\":\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
